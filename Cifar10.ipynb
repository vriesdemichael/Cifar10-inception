{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\deep\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Concatenate, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine.topology import get_source_inputs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition\n",
    "The network has a stem at the start, followed by multiple inception blocks.\n",
    "After the inception blocks a globalaverage is applied followed by a dense output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stem():\n",
    "    img_input = Input(shape=(32, 32, 3))\n",
    "    stem = Conv2D(32, 3, strides=2, padding=\"same\", name=\"stem-conv-1\")(img_input)\n",
    "    stem = Conv2D(32, 3, strides=1, padding=\"same\", name=\"stem-conv-2\")(stem)\n",
    "    stem = Conv2D(64, 3, strides=1, padding=\"same\", name=\"stem-conv-3\")(stem)\n",
    "    stem = MaxPool2D(3, strides=2)(stem)\n",
    "    stem = Conv2D(80, 1, padding=\"same\", name=\"stem-conv-4\")(stem)\n",
    "    stem = Conv2D(192, 3, padding=\"same\", name=\"stem-conv-5\")(stem)\n",
    "    stem = MaxPool2D(3, strides=2, name=\"stem-maxpool2\")(stem)\n",
    "    return stem, get_source_inputs(img_input)\n",
    "\n",
    "\n",
    "def get_flower(inceptions):\n",
    "    flower = GlobalAveragePooling2D(name=\"flower-globalaverage\")(inceptions)\n",
    "    flower = Dropout(0.2)(flower)\n",
    "    flower = Dense(10, activation=\"softmax\")(flower)\n",
    "    return flower\n",
    "    \n",
    "def add_inception(previous, count=1):\n",
    "    \n",
    "    # 1x1\n",
    "    branch1x1 = Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\", name=\"inception-{}-1x1\".format(count))(previous)\n",
    "    \n",
    "    # 3x3\n",
    "    branch3x3 = Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\", name=\"inception-{}-3x3-1\".format(count))(previous)\n",
    "    branch3x3 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"inception-{}-3x3-2\".format(count))(branch3x3)\n",
    "    \n",
    "    # 5x5\n",
    "    branch5x5 = Conv2D(48, (1, 1), padding=\"same\", activation=\"relu\", name=\"inception-{}-5x5-1\".format(count))(previous)\n",
    "    branch5x5 = Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\", name=\"inception-{}-5x5-2\".format(count))(branch5x5)\n",
    "    \n",
    "    # 3x3 pooling\n",
    "    branch_pool = MaxPool2D((3, 3), strides=(1, 1), padding=\"same\", name=\"inception-{}-pool-1\".format(count))(previous)\n",
    "    branch_pool = Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\", name=\"inception-{}-pool-2\".format(count))(branch_pool)\n",
    "    \n",
    "    next = Concatenate(axis=3, name=\"inception-{}-concat\".format(count))([branch1x1, branch3x3, branch5x5, branch_pool])\n",
    "    return next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem-conv-1 (Conv2D)            (None, 16, 16, 32)   896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem-conv-2 (Conv2D)            (None, 16, 16, 32)   9248        stem-conv-1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem-conv-3 (Conv2D)            (None, 16, 16, 64)   18496       stem-conv-2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)     0           stem-conv-3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem-conv-4 (Conv2D)            (None, 7, 7, 80)     5200        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stem-conv-5 (Conv2D)            (None, 7, 7, 192)    138432      stem-conv-4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "stem-maxpool2 (MaxPooling2D)    (None, 3, 3, 192)    0           stem-conv-5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-3x3-1 (Conv2D)      (None, 3, 3, 64)     12352       stem-maxpool2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-5x5-1 (Conv2D)      (None, 3, 3, 48)     9264        stem-maxpool2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-pool-1 (MaxPooling2 (None, 3, 3, 192)    0           stem-maxpool2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-1x1 (Conv2D)        (None, 3, 3, 64)     12352       stem-maxpool2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-3x3-2 (Conv2D)      (None, 3, 3, 64)     36928       inception-1-3x3-1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-5x5-2 (Conv2D)      (None, 3, 3, 64)     76864       inception-1-5x5-1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-pool-2 (Conv2D)     (None, 3, 3, 64)     12352       inception-1-pool-1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inception-1-concat (Concatenate (None, 3, 3, 256)    0           inception-1-1x1[0][0]            \n",
      "                                                                 inception-1-3x3-2[0][0]          \n",
      "                                                                 inception-1-5x5-2[0][0]          \n",
      "                                                                 inception-1-pool-2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flower-globalaverage (GlobalAve (None, 256)          0           inception-1-concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           flower-globalaverage[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           2570        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 334,954\n",
      "Trainable params: 334,954\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stem, img_input = create_stem()\n",
    "output = add_inception(stem, count=1)\n",
    "# for i in range(2, 2):\n",
    "#     output = add_inception(output, count=i)\n",
    "flower = get_flower(output)\n",
    "\n",
    "model = Model(img_input, flower, name='inception_gen')\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The model will be saved afterwards (and overwritten) as `model.h5`. A tensorboard log will be written. The tensorboard can be started with ```tensorboard --logdir=c:/tmp/logs/``` and visited at [http://michael-laptop:6006](http://michael-laptop:6006/#scalars&tagFilter=acc&regexInput=cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run cifar10-Wed-16.12 \n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 1.4116 - acc: 0.4897 - val_loss: 1.0157 - val_acc: 0.6402\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64020, saving model to model_checkpoint.h5\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 0.9523 - acc: 0.6652 - val_loss: 0.8735 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64020 to 0.69640, saving model to model_checkpoint.h5\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7925 - acc: 0.7240 - val_loss: 0.8450 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69640 to 0.70710, saving model to model_checkpoint.h5\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 17s 343us/step - loss: 0.6967 - acc: 0.7561 - val_loss: 0.7366 - val_acc: 0.7469\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70710 to 0.74690, saving model to model_checkpoint.h5\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.6247 - acc: 0.7830 - val_loss: 0.7149 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74690 to 0.75300, saving model to model_checkpoint.h5\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.5549 - acc: 0.8061 - val_loss: 0.7029 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.75300 to 0.76170, saving model to model_checkpoint.h5\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.5009 - acc: 0.8249 - val_loss: 0.7239 - val_acc: 0.7690\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.76170 to 0.76900, saving model to model_checkpoint.h5\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.4558 - acc: 0.8404 - val_loss: 0.7491 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76900\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 0.4129 - acc: 0.8540 - val_loss: 0.7731 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76900\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.3816 - acc: 0.8660 - val_loss: 0.8260 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76900\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 0.3439 - acc: 0.8789 - val_loss: 0.7897 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.76900 to 0.77210, saving model to model_checkpoint.h5\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 0.3264 - acc: 0.8838 - val_loss: 0.8020 - val_acc: 0.7719\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.77210\n",
      "Epoch 13/100\n",
      "49344/50000 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8930"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from time import strftime\n",
    "\n",
    "model_path = \"model_checkpoint.h5\"\n",
    "run_name = \"cifar10-{}\".format(strftime('%a-%H.%M'))\n",
    "print(\"Starting run {} \".format(run_name))\n",
    "\n",
    "cbs = [\n",
    "    TensorBoard(log_dir=\"../logs/{}\".format(run_name)),\n",
    "    EarlyStopping(monitor=\"val_acc\", patience=20, verbose=1),\n",
    "    ModelCheckpoint(model_path, monitor=\"val_acc\", save_best_only=True, save_weights_only=False, verbose=1)\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=[x_test, y_test], callbacks=cbs)\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"custom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
